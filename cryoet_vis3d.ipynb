{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T21:03:22.674816Z",
     "iopub.status.busy": "2024-12-25T21:03:22.674434Z",
     "iopub.status.idle": "2024-12-25T21:03:29.794485Z",
     "shell.execute_reply": "2024-12-25T21:03:29.793436Z",
     "shell.execute_reply.started": "2024-12-25T21:03:22.674782Z"
    },
    "executionInfo": {
     "elapsed": 2651,
     "status": "ok",
     "timestamp": 1735219924812,
     "user": {
      "displayName": "Lino Riepenhausen",
      "userId": "07445831505464583178"
     },
     "user_tz": -60
    },
    "id": "NC3tFBgrCPBk",
    "outputId": "104ee4d2-359e-4ea4-88ad-1efd23ac642b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch numpy pandas zarr tqdm scikit-learn matplotlib json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import shutil\n",
    "import logging\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.utils.checkpoint\n",
    "from torch.nn.parallel import DataParallel\n",
    "\n",
    "from torch.optim.lr_scheduler import (\n",
    "    CosineAnnealingLR,\n",
    "    OneCycleLR\n",
    ")\n",
    "\n",
    "import zarr\n",
    "from zarr.storage import DirectoryStore\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "from typing import (\n",
    "    Dict,\n",
    "    List,\n",
    "    Tuple,\n",
    "    Optional,\n",
    "    Union,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Iterator,\n",
    "    Sequence,\n",
    "    TypeVar,\n",
    "    Generic,\n",
    "    Protocol,\n",
    "    runtime_checkable\n",
    ")\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "PathLike = Union[str, Path]\n",
    "JsonDict = Dict[str, Any]\n",
    "ModelOutput = Dict[str, torch.Tensor]\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Fix random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def process_json_files(base_dir, experiments, particle_types, output_dir):\n",
    "    \"\"\"Process all JSON files and save to output directory\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for experiment in experiments:\n",
    "        for particle_type in particle_types:\n",
    "            if particle_type == \"beta-amylase\":\n",
    "                continue\n",
    "                \n",
    "            input_path = os.path.join(\n",
    "                base_dir, \n",
    "                f\"train/overlay/ExperimentRuns/{experiment}/Picks/{particle_type}.json\"\n",
    "            )\n",
    "            output_path = os.path.join(\n",
    "                output_dir, \n",
    "                f\"{experiment}_{particle_type}_processed.json\"\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(input_path):\n",
    "                print(f\"File not found: {input_path}\")\n",
    "                continue\n",
    "                \n",
    "            with open(input_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            if \"points\" not in data:\n",
    "                print(f\"No points found in {input_path}\")\n",
    "                continue\n",
    "                \n",
    "            processed_points = [\n",
    "                {\n",
    "                    \"x\": p[\"location\"][\"x\"],\n",
    "                    \"y\": p[\"location\"][\"y\"],\n",
    "                    \"z\": p[\"location\"][\"z\"]\n",
    "                }\n",
    "                for p in data[\"points\"]\n",
    "            ]\n",
    "            \n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(processed_points, f, indent=2)\n",
    "            print(f\"Processed {input_path} -> {output_path}\")\n",
    "\n",
    "class CryoET3DDataset(Dataset):\n",
    "    \"\"\"Dataset class for 3D CryoET data\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        zarr_path,\n",
    "        labels=None,\n",
    "        particle_type=None, \n",
    "        patch_size=(64, 128, 128),\n",
    "        stride_3d=(32, 64, 64),\n",
    "        skip_negatives_ratio=0.7,\n",
    "        max_patches=4000,\n",
    "        normalize_coords=True,\n",
    "        voxel_size=10.0,\n",
    "        origin_offset=(0, 0, 0),\n",
    "        augment=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.zarr_path = zarr_path\n",
    "        self.labels = labels if labels else []\n",
    "        self.particle_type = particle_type\n",
    "        self.patch_d, self.patch_h, self.patch_w = patch_size\n",
    "        self.stride_d, self.stride_h, self.stride_w = stride_3d\n",
    "        self.skip_negatives_ratio = skip_negatives_ratio\n",
    "        self.max_patches = max_patches\n",
    "        self.normalize_coords = normalize_coords\n",
    "        self.voxel_size = voxel_size\n",
    "        self.origin_offset = origin_offset\n",
    "        self.augment = augment\n",
    "\n",
    "        \n",
    "        self.particle_types = [\n",
    "            \"apo-ferritin\",\n",
    "            \"beta-galactosidase\",\n",
    "            \"ribosome\",\n",
    "            \"thyroglobulin\",\n",
    "            \"virus-like-particle\"\n",
    "        ]\n",
    "        self.particle_type_to_idx = {\n",
    "            ptype: idx for idx, ptype in enumerate(self.particle_types)\n",
    "        }\n",
    "\n",
    "        self.volume = self._load_and_normalize_zarr()\n",
    "        self.D, self.H, self.W = self.volume.shape\n",
    "        \n",
    "        self._normalize_labels()\n",
    "        self.patch_positions = self._build_balanced_patches()\n",
    "        \n",
    "    def _load_and_normalize_zarr(self):\n",
    "        \"\"\"Load and normalize the volume data\"\"\"\n",
    "        store = DirectoryStore(self.zarr_path)\n",
    "        zf = zarr.open(store, mode='r')\n",
    "        volume = zf[\"0\"][:] \n",
    "\n",
    "        mean = np.mean(volume)\n",
    "        std = np.std(volume)\n",
    "        volume = (volume - mean) / (std + 1e-6)\n",
    "\n",
    "        p2, p98 = np.percentile(volume, (2, 98))\n",
    "        volume = np.clip(volume, p2, p98)\n",
    "        volume = (volume - p2) / (p98 - p2 + 1e-6)\n",
    "\n",
    "        return volume\n",
    "        \n",
    "    def _normalize_labels(self):\n",
    "        \"\"\"Convert raw coordinates to voxel space\"\"\"\n",
    "        scaled = []\n",
    "        for lbl in self.labels:\n",
    "            rx, ry, rz = lbl[\"x\"], lbl[\"y\"], lbl[\"z\"]\n",
    "            vx = (rx - self.origin_offset[0]) / self.voxel_size\n",
    "            vy = (ry - self.origin_offset[1]) / self.voxel_size\n",
    "            vz = (rz - self.origin_offset[2]) / self.voxel_size\n",
    "            \n",
    "            if 0 <= vx < self.W and 0 <= vy < self.H and 0 <= vz < self.D:\n",
    "                scaled.append({\"x\": vx, \"y\": vy, \"z\": vz})\n",
    "                \n",
    "        self.labels = scaled\n",
    "        \n",
    "    def _build_balanced_patches(self):\n",
    "        \"\"\"Create balanced positive/negative patches\"\"\"\n",
    "        positions = []\n",
    "        positive_positions = []\n",
    "        negative_positions = []\n",
    "\n",
    "        for z in range(0, self.D - self.patch_d + 1, self.stride_d):\n",
    "            for y in range(0, self.H - self.patch_h + 1, self.stride_h):\n",
    "                for x in range(0, self.W - self.patch_w + 1, self.stride_w):\n",
    "                    pos = (z, y, x)\n",
    "                    if self._has_particle_in_patch(pos):\n",
    "                        positive_positions.append(pos)\n",
    "                    else:\n",
    "                        negative_positions.append(pos)\n",
    "\n",
    "        num_positives = len(positive_positions)\n",
    "        if num_positives == 0:\n",
    "            num_samples = min(self.max_patches, len(negative_positions))\n",
    "            positions = random.sample(negative_positions, num_samples)\n",
    "        else:\n",
    "            neg_factor = (1 / max(self.skip_negatives_ratio, 1e-6) - 1)\n",
    "            num_negatives = min(\n",
    "                int(num_positives * neg_factor),\n",
    "                len(negative_positions)\n",
    "            )\n",
    "            sampled_negatives = random.sample(negative_positions, num_negatives)\n",
    "            positions = positive_positions + sampled_negatives\n",
    "\n",
    "        random.shuffle(positions)\n",
    "        if self.max_patches:\n",
    "            positions = positions[:self.max_patches]\n",
    "\n",
    "        return positions\n",
    "        \n",
    "    def _has_particle_in_patch(self, pos):\n",
    "        \"\"\"Check if patch contains a particle\"\"\"\n",
    "        z0, y0, x0 = pos\n",
    "        z1, y1, x1 = z0 + self.patch_d, y0 + self.patch_h, x0 + self.patch_w\n",
    "        \n",
    "        for lbl in self.labels:\n",
    "            if (x0 <= lbl[\"x\"] < x1 and \n",
    "                y0 <= lbl[\"y\"] < y1 and \n",
    "                z0 <= lbl[\"z\"] < z1):\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    def _create_particle_type_tensor(self):\n",
    "        \"\"\"Create one-hot encoded tensor for particle type\"\"\"\n",
    "        encoding = torch.zeros(len(self.particle_types))\n",
    "        if self.particle_type in self.particle_type_to_idx:\n",
    "            encoding[self.particle_type_to_idx[self.particle_type]] = 1.0\n",
    "        return encoding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patch_positions)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        z0, y0, x0 = self.patch_positions[idx]\n",
    "        z1, y1, x1 = z0 + self.patch_d, y0 + self.patch_h, x0 + self.patch_w\n",
    "    \n",
    "        patch_data = self.volume[z0:z1, y0:y1, x0:x1]\n",
    "    \n",
    "        if self.augment:\n",
    "            if random.random() < 0.5:\n",
    "                patch_data = patch_data[::-1, :, :]   \n",
    "            if random.random() < 0.5:\n",
    "                patch_data = patch_data[:, ::-1, :]  \n",
    "            if random.random() < 0.5:\n",
    "                patch_data = patch_data[:, :, ::-1] \n",
    "        \n",
    "        patch_data = patch_data.copy()\n",
    "    \n",
    "        patch_tensor = torch.tensor(patch_data, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "        cls_label = 0\n",
    "        coord_label = torch.zeros(3, dtype=torch.float32)\n",
    "        particle_type_label = self._create_particle_type_tensor()\n",
    "    \n",
    "        picks_in_patch = [\n",
    "            {\"x\": lbl[\"x\"] - x0, \"y\": lbl[\"y\"] - y0, \"z\": lbl[\"z\"] - z0}\n",
    "            for lbl in self.labels\n",
    "            if x0 <= lbl[\"x\"] < x1 and y0 <= lbl[\"y\"] < y1 and z0 <= lbl[\"z\"] < z1\n",
    "        ]\n",
    "    \n",
    "        if len(picks_in_patch) == 1:\n",
    "            cls_label = 1\n",
    "            px, py, pz = picks_in_patch[0][\"x\"], picks_in_patch[0][\"y\"], picks_in_patch[0][\"z\"]\n",
    "            if self.normalize_coords:\n",
    "                coord_label = torch.tensor([px / self.patch_w, py / self.patch_h, pz / self.patch_d], dtype=torch.float32)\n",
    "            else:\n",
    "                coord_label = torch.tensor([px, py, pz], dtype=torch.float32)\n",
    "    \n",
    "        return patch_tensor, {\n",
    "            \"class\": torch.tensor(cls_label, dtype=torch.long),\n",
    "            \"coords\": coord_label,\n",
    "            \"particle_type\": particle_type_label,\n",
    "            \"offset\": torch.tensor([z0, y0, x0], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "def build_datasets(base_dir, particle_types, experiments, patch_size, stride_3d, \n",
    "                  max_patches, output_dir, val_split=0.2):\n",
    "    \"\"\"Build training and validation datasets\"\"\"\n",
    "    \n",
    "    num_val = int(len(experiments) * val_split)\n",
    "    train_experiments = experiments[:-num_val]\n",
    "    val_experiments = experiments[-num_val:]\n",
    "    \n",
    "    def build_dataset(exps):\n",
    "        datasets = []\n",
    "        for experiment in exps:\n",
    "            for ptype in particle_types:\n",
    "                if ptype == \"beta-amylase\":\n",
    "                    continue\n",
    "\n",
    "                zarr_path = os.path.join(\n",
    "                    base_dir,\n",
    "                    f\"train/static/ExperimentRuns/{experiment}/VoxelSpacing10.000/denoised.zarr\"\n",
    "                )\n",
    "                json_file = os.path.join(output_dir, f\"{experiment}_{ptype}_processed.json\")\n",
    "\n",
    "                if not os.path.exists(json_file):\n",
    "                    continue\n",
    "\n",
    "                with open(json_file, 'r') as f:\n",
    "                    labels = json.load(f)\n",
    "\n",
    "                try:\n",
    "                    dataset = CryoET3DDataset(\n",
    "                        zarr_path=zarr_path,\n",
    "                        labels=labels,\n",
    "                        particle_type=ptype,  \n",
    "                        patch_size=patch_size,\n",
    "                        stride_3d=stride_3d,\n",
    "                        skip_negatives_ratio=0.7,\n",
    "                        max_patches=max_patches,\n",
    "                        normalize_coords=True,\n",
    "                        augment=True\n",
    "                    )\n",
    "                    datasets.append(dataset)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error building dataset for {experiment}-{ptype}: {e}\")\n",
    "\n",
    "        if not datasets:\n",
    "            raise ValueError(\"No valid datasets found\")\n",
    "        return ConcatDataset(datasets)\n",
    "    \n",
    "    train_dataset = build_dataset(train_experiments)\n",
    "    val_dataset = build_dataset(val_experiments)\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
    "    def __init__(self, channels, reduction_ratio=16):\n",
    "        super().__init__()\n",
    "        reduced_channels = max(channels // reduction_ratio, 8)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc1 = nn.Conv3d(channels, reduced_channels, 1)\n",
    "        self.fc2 = nn.Conv3d(reduced_channels, channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        squeeze = self.avg_pool(x)\n",
    "        excitation = F.relu(self.fc1(squeeze))\n",
    "        excitation = torch.sigmoid(self.fc2(excitation))\n",
    "        return x * excitation\n",
    "\n",
    "class ResidualBlock3D(nn.Module):\n",
    "    \"\"\"3D Residual block with squeeze-excitation\"\"\"\n",
    "    def __init__(self, channels, se_ratio=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(channels)\n",
    "        self.conv2 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(channels)\n",
    "        self.se = SqueezeExcitation(channels, se_ratio)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.se(out)\n",
    "        out += residual\n",
    "        return F.relu(out)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class AxialAttention(nn.Module):\n",
    "    \"\"\"Memory-efficient axial attention for 3D data\"\"\"\n",
    "    def __init__(self, dim, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        self.qkv_d = nn.Linear(dim, dim * 3)\n",
    "        self.qkv_h = nn.Linear(dim, dim * 3)\n",
    "        self.qkv_w = nn.Linear(dim, dim * 3)\n",
    "\n",
    "        self.proj_d = nn.Linear(dim, dim)\n",
    "        self.proj_h = nn.Linear(dim, dim)\n",
    "        self.proj_w = nn.Linear(dim, dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 5, f\"Expected 5D input (B, D, H, W, C), but got {x.shape}\"\n",
    "        B, D, H, W, C = x.shape\n",
    "\n",
    "        def attention(x, qkv_proj, proj):\n",
    "            shape = x.shape\n",
    "            x = x.reshape(-1, shape[-2], C) \n",
    "            qkv = qkv_proj(x).reshape(-1, shape[-2], 3, self.num_heads, self.head_dim)\n",
    "            qkv = qkv.permute(2, 0, 3, 1, 4) \n",
    "            q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "            attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "            attn = attn.softmax(dim=-1)\n",
    "            attn = self.dropout(attn)\n",
    "\n",
    "            x = (attn @ v).transpose(1, 2).reshape(-1, shape[-2], C)\n",
    "            x = proj(x).reshape(shape)\n",
    "            return x\n",
    "\n",
    "        x_d = attention(x.permute(0, 2, 3, 1, 4), self.qkv_d, self.proj_d)\n",
    "        x_h = attention(x.permute(0, 1, 3, 2, 4), self.qkv_h, self.proj_h)\n",
    "        x_w = attention(x.permute(0, 1, 2, 3, 4), self.qkv_w, self.proj_w)\n",
    "\n",
    "        return x_d.permute(0, 3, 1, 2, 4) + x_h.permute(0, 1, 3, 2, 4) + x_w\n",
    "\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
    "    def __init__(self, channels, reduction_ratio=16):\n",
    "        super().__init__()\n",
    "        reduced_channels = max(channels // reduction_ratio, 8)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc1 = nn.Conv3d(channels, reduced_channels, kernel_size=1)\n",
    "        self.fc2 = nn.Conv3d(reduced_channels, channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        squeeze = self.avg_pool(x)  \n",
    "        excitation = F.relu(self.fc1(squeeze))  \n",
    "        excitation = torch.sigmoid(self.fc2(excitation))  \n",
    "        return x * excitation \n",
    "\n",
    "\n",
    "class ResidualBlock3D(nn.Module):\n",
    "    \"\"\"3D Residual block with squeeze-excitation\"\"\"\n",
    "    def __init__(self, channels, se_ratio=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(channels)\n",
    "        self.conv2 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(channels)\n",
    "        self.se = SqueezeExcitation(channels, se_ratio)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  \n",
    "        out = self.bn2(self.conv2(out))  \n",
    "        out = self.se(out) \n",
    "        out += residual \n",
    "        return F.relu(out)  \n",
    "\n",
    "class ImprovedFeaturePyramid(nn.Module):\n",
    "    \"\"\"Feature Pyramid with residual connections\"\"\"\n",
    "    def __init__(self, in_dim=1, dim=512):\n",
    "        super().__init__()\n",
    "        self.init_conv = nn.Conv3d(in_dim, dim, kernel_size=1)\n",
    "\n",
    "        self.down = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                ResidualBlock3D(dim),\n",
    "                nn.Conv3d(dim, dim, kernel_size=2, stride=2)\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "\n",
    "        self.lateral = nn.ModuleList([\n",
    "            nn.Conv3d(dim, dim, kernel_size=1)\n",
    "            for _ in range(3)\n",
    "        ])\n",
    "\n",
    "        self.up = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose3d(dim, dim, kernel_size=2, stride=2),\n",
    "                ResidualBlock3D(dim)\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "\n",
    "        self.se = nn.ModuleList([\n",
    "            SqueezeExcitation(dim)\n",
    "            for _ in range(4)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init_conv(x)\n",
    "        features = [self.se[0](x)]  \n",
    "\n",
    "        for i, down in enumerate(self.down):\n",
    "            x = down(x)\n",
    "            features.append(self.se[i + 1](x))\n",
    "\n",
    "        laterals = [lateral(feat) for feat, lateral in zip(features, self.lateral)]\n",
    "\n",
    "        results = [features[-1]]\n",
    "        x = features[-1]\n",
    "\n",
    "        for up, skip in zip(self.up, laterals[::-1]):\n",
    "            x = up(x)\n",
    "            if x.shape != skip.shape:\n",
    "                x = F.interpolate(x, size=skip.shape[2:], mode='trilinear', align_corners=False)\n",
    "            x = x + skip\n",
    "            results.append(x)\n",
    "\n",
    "        return results  \n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Transformer block with axial attention\"\"\"\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4.0, dropout=0.1, drop_path=0.0, use_checkpointing=True):\n",
    "        super().__init__()\n",
    "        self.use_checkpointing = use_checkpointing\n",
    "        self.drop_path = drop_path\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = AxialAttention(dim, num_heads, dropout)\n",
    "        \n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.use_checkpointing and self.training:\n",
    "            x = x + self._drop_path(torch.utils.checkpoint.checkpoint(self.attn, self.norm1(x)))\n",
    "            x = x + self._drop_path(torch.utils.checkpoint.checkpoint(self.mlp, self.norm2(x)))\n",
    "        else:\n",
    "            x = x + self._drop_path(self.attn(self.norm1(x)))\n",
    "            x = x + self._drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "        \n",
    "    def _drop_path(self, x):\n",
    "        if self.drop_path > 0.0 and self.training:\n",
    "            keep_prob = 1 - self.drop_path\n",
    "            mask = torch.zeros_like(x[0, 0]).bernoulli_(keep_prob)\n",
    "            mask = mask / keep_prob\n",
    "            mask = mask.expand_as(x)\n",
    "            return x * mask\n",
    "        return x\n",
    "\n",
    "class ImprovedViT3D(nn.Module):\n",
    "    \"\"\"Improved Vision Transformer 3D\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_size=(8, 16, 16),\n",
    "        in_chans=1,\n",
    "        embed_dim=512,\n",
    "        depth=12,\n",
    "        num_heads=16,\n",
    "        mlp_ratio=4.0,\n",
    "        num_classes=2,\n",
    "        num_particle_types=5,\n",
    "        dropout=0.1,\n",
    "        stochastic_depth_prob=0.1,\n",
    "        use_checkpointing=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_pyramid = ImprovedFeaturePyramid(in_chans, embed_dim // 4)\n",
    "\n",
    "        self.patch_embed = nn.Conv3d(\n",
    "            in_chans, embed_dim, kernel_size=patch_size, stride=patch_size\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, 100, embed_dim)) \n",
    "        self.pos_drop = nn.Dropout(dropout)\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(0, stochastic_depth_prob, depth)]\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                dropout=dropout,\n",
    "                drop_path=dpr[i],\n",
    "                use_checkpointing=use_checkpointing\n",
    "            )\n",
    "            for i in range(depth)\n",
    "        ])\n",
    "\n",
    "        self.final_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.class_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "        self.coord_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim // 2, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.particle_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim // 2, num_particle_types),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        \"\"\"Initialize weights\"\"\"\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.ones_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the ViT3D model.\n",
    "        Expected input: [B, C, D, H, W]\n",
    "        AxialAttention expects [B, D, H, W, C].\n",
    "        \"\"\"\n",
    "        _ = self.feature_pyramid(x)  \n",
    "    \n",
    "        x = self.patch_embed(x)\n",
    "        B, C, D, H, W = x.shape  \n",
    "    \n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "    \n",
    "        x = self.norm(x)  \n",
    "    \n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)  \n",
    "    \n",
    "        x = self.final_norm(x)\n",
    "    \n",
    "        x = x.mean(dim=(1, 2, 3))\n",
    "    \n",
    "        return {\n",
    "            'logits': self.class_head(x),\n",
    "            'coords': self.coord_head(x),\n",
    "            'particle_types': self.particle_head(x)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    \"\"\"Focal loss for better handling of class imbalance\"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=15,\n",
    "    save_dir='checkpoints',\n",
    "    model_id=0\n",
    "):\n",
    "    \"\"\"Training function with proper device handling and mixed precision\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    model = model.to('cuda:0')\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=2e-4,\n",
    "        weight_decay=0.05,\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=2e-4,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        div_factor=25,\n",
    "        final_div_factor=1000\n",
    "    )\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    class_weights = torch.tensor([1.0, 10.0]).to('cuda:0')\n",
    "    focal_loss = FocalLoss(alpha=class_weights, gamma=2.0)\n",
    "    coord_loss = nn.SmoothL1Loss()\n",
    "    particle_loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (volumes, meta) in enumerate(train_loader):\n",
    "            volumes = volumes.to('cuda:0')\n",
    "            class_labels = meta['class'].to('cuda:0')\n",
    "            coord_labels = meta['coords'].to('cuda:0')\n",
    "            particle_type_labels = meta['particle_type'].to('cuda:0')\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(volumes)\n",
    "                \n",
    "                class_loss = focal_loss(outputs['logits'], class_labels)\n",
    "                \n",
    "                pos_mask = (class_labels == 1)\n",
    "                if pos_mask.any():\n",
    "                    coord_loss_val = coord_loss(outputs['coords'][pos_mask], coord_labels[pos_mask])\n",
    "                    particle_loss_val = particle_loss(outputs['particle_types'][pos_mask], particle_type_labels[pos_mask])\n",
    "                else:\n",
    "                    coord_loss_val = torch.tensor(0.0, device='cuda:0')\n",
    "                    particle_loss_val = torch.tensor(0.0, device='cuda:0')\n",
    "                \n",
    "                loss = class_loss + 2.0 * coord_loss_val + 0.5 * particle_loss_val\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f'Epoch: {epoch+1}/{num_epochs} | Batch: {batch_idx}/{len(train_loader)} | '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for volumes, meta in val_loader:\n",
    "                volumes = volumes.to('cuda:0')\n",
    "                class_labels = meta['class'].to('cuda:0')\n",
    "                coord_labels = meta['coords'].to('cuda:0')\n",
    "                particle_type_labels = meta['particle_type'].to('cuda:0')\n",
    "                \n",
    "                with autocast():\n",
    "                    outputs = model(volumes)\n",
    "                    class_loss = focal_loss(outputs['logits'], class_labels)\n",
    "                    \n",
    "                    pos_mask = (class_labels == 1)\n",
    "                    if pos_mask.any():\n",
    "                        coord_loss_val = coord_loss(outputs['coords'][pos_mask], coord_labels[pos_mask])\n",
    "                        particle_loss_val = particle_loss(outputs['particle_types'][pos_mask], particle_type_labels[pos_mask])\n",
    "                    else:\n",
    "                        coord_loss_val = torch.tensor(0.0, device='cuda:0')\n",
    "                        particle_loss_val = torch.tensor(0.0, device='cuda:0')\n",
    "                    \n",
    "                    loss = class_loss + 2.0 * coord_loss_val + 0.5 * particle_loss_val\n",
    "                    val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f'\\nEpoch {epoch+1} Summary:')\n",
    "        print(f'Training Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience = 0\n",
    "            save_path = os.path.join(save_dir, f'model_{model_id}_best.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_loss': best_val_loss\n",
    "            }, save_path)\n",
    "            print(f'Saved best model to {save_path}')\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 5:\n",
    "                print('Early stopping triggered')\n",
    "                break\n",
    "    \n",
    "    return model\n",
    "\n",
    "def validate_model(model, val_loader, device, focal_loss, coord_loss, particle_loss):\n",
    "    \"\"\"Validation function with autocast-safe losses\"\"\"\n",
    "    model.eval()\n",
    "    val_losses = {'total': 0.0, 'class': 0.0, 'coord': 0.0, 'particle': 0.0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for volumes, meta in val_loader:\n",
    "            volumes = volumes.to(device)\n",
    "            class_labels = meta[\"class\"].to(device)\n",
    "            coord_labels = meta[\"coords\"].to(device)\n",
    "            particle_type_labels = meta[\"particle_type\"].to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(volumes)\n",
    "                loss_class = focal_loss(outputs['logits'], class_labels)\n",
    "                \n",
    "                pos_mask = (class_labels == 1)\n",
    "                if pos_mask.any():\n",
    "                    loss_coords = coord_loss(\n",
    "                        outputs['coords'][pos_mask],\n",
    "                        coord_labels[pos_mask]\n",
    "                    )\n",
    "                    loss_particle = particle_loss(\n",
    "                        outputs['particle_types'][pos_mask],\n",
    "                        particle_type_labels[pos_mask]\n",
    "                    )\n",
    "                else:\n",
    "                    loss_coords = torch.tensor(0.0, device=device)\n",
    "                    loss_particle = torch.tensor(0.0, device=device)\n",
    "                \n",
    "                total_loss = loss_class + 2.0 * loss_coords + 0.5 * loss_particle\n",
    "            \n",
    "            val_losses['total'] += total_loss.item()\n",
    "            val_losses['class'] += loss_class.item()\n",
    "            val_losses['coord'] += loss_coords.item()\n",
    "            val_losses['particle'] += loss_particle.item()\n",
    "    \n",
    "    return val_losses['total'] / len(val_loader)\n",
    "\n",
    "def validate_model(model, val_loader, device, focal_loss, coord_loss, particle_loss):\n",
    "    \"\"\"Validation function with detailed metrics\"\"\"\n",
    "    model.eval()\n",
    "    val_losses = {'total': 0.0, 'class': 0.0, 'coord': 0.0, 'particle': 0.0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for volumes, meta in val_loader:\n",
    "            volumes = volumes.to(device)\n",
    "            class_labels = meta[\"class\"].to(device)\n",
    "            coord_labels = meta[\"coords\"].to(device)\n",
    "            \n",
    "            outputs = model(volumes)\n",
    "            \n",
    "            loss_class = focal_loss(outputs['logits'], class_labels)\n",
    "            \n",
    "            pos_mask = (class_labels == 1)\n",
    "            if pos_mask.any():\n",
    "                loss_coords = coord_loss(\n",
    "                    outputs['coords'][pos_mask],\n",
    "                    coord_labels[pos_mask]\n",
    "                )\n",
    "                loss_particle = particle_loss(\n",
    "                    outputs['particle_types'][pos_mask],\n",
    "                    meta['particle_type'].to(device)[pos_mask]\n",
    "                )\n",
    "            else:\n",
    "                loss_coords = torch.tensor(0.0, device=device)\n",
    "                loss_particle = torch.tensor(0.0, device=device)\n",
    "            \n",
    "            total_loss = loss_class + 2.0 * loss_coords + 0.5 * loss_particle\n",
    "            \n",
    "            val_losses['total'] += total_loss.item()\n",
    "            val_losses['class'] += loss_class.item()\n",
    "            val_losses['coord'] += loss_coords.item()\n",
    "            val_losses['particle'] += loss_particle.item()\n",
    "    \n",
    "    return val_losses['total'] / len(val_loader)\n",
    "\n",
    "def predict_ensemble(models, zarr_path, patch_size, stride_3d, device=\"cuda\", threshold=0.85):\n",
    "    \"\"\"Ensemble prediction with multi-GPU and test-time augmentation\"\"\"\n",
    "    for model in models:\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = DataParallel(model)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "    dataset = CryoET3DDataset(\n",
    "        zarr_path=zarr_path,\n",
    "        labels=[],\n",
    "        patch_size=patch_size,\n",
    "        stride_3d=stride_3d,\n",
    "        skip_negatives_ratio=0.0,\n",
    "        max_patches=None,\n",
    "        normalize_coords=True,\n",
    "        augment=False\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=8, num_workers=4, pin_memory=True)\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for volumes, meta in loader:\n",
    "            volumes = volumes.to(device)\n",
    "            offsets = meta[\"offset\"]\n",
    "\n",
    "            ensemble_probs = []\n",
    "            ensemble_coords = []\n",
    "\n",
    "            for model in models:\n",
    "                class_logits, coords = model(volumes)\n",
    "                probs = F.softmax(class_logits, dim=-1)[:, 1]\n",
    "                ensemble_probs.append(probs.unsqueeze(0))\n",
    "                ensemble_coords.append(coords.unsqueeze(0))\n",
    "\n",
    "            mean_probs = torch.cat(ensemble_probs, dim=0).mean(0)\n",
    "            mean_coords = torch.cat(ensemble_coords, dim=0).mean(0)\n",
    "\n",
    "            for i in range(len(volumes)):\n",
    "                if mean_probs[i] >= threshold:\n",
    "                    coord = mean_coords[i].cpu().numpy()\n",
    "                    z0, y0, x0 = offsets[i].tolist()\n",
    "\n",
    "                    px = coord[0] * patch_size[2]\n",
    "                    py = coord[1] * patch_size[1]\n",
    "                    pz = coord[2] * patch_size[0]\n",
    "\n",
    "                    gx = float(px + x0) * 10.0\n",
    "                    gy = float(py + y0) * 10.0\n",
    "                    gz = float(pz + z0) * 10.0\n",
    "\n",
    "                    predictions.append({\n",
    "                        \"x\": round(gx, 2),\n",
    "                        \"y\": round(gy, 2),\n",
    "                        \"z\": round(gz, 2),\n",
    "                        \"prob\": float(mean_probs[i].cpu().item())\n",
    "                    })\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def nms_3d(predictions, iou_threshold=0.3, radius=15):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression to 3D predictions\n",
    "    Args:\n",
    "        predictions: List of dictionaries containing predictions with x, y, z coordinates and prob scores\n",
    "        iou_threshold: Distance threshold for suppression\n",
    "        radius: Radius around each point to consider for suppression\n",
    "    Returns:\n",
    "        List of filtered predictions\n",
    "    \"\"\"\n",
    "    if not predictions:\n",
    "        return []\n",
    "    \n",
    "    predictions = sorted(predictions, key=lambda x: x['prob'], reverse=True)\n",
    "    kept_predictions = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        should_keep = True\n",
    "        for kept in kept_predictions:\n",
    "            dist = ((pred['x'] - kept['x'])**2 + \n",
    "                   (pred['y'] - kept['y'])**2 + \n",
    "                   (pred['z'] - kept['z'])**2)**0.5\n",
    "            \n",
    "            if dist < radius:\n",
    "                should_keep = False\n",
    "                break\n",
    "        \n",
    "        if should_keep:\n",
    "            kept_predictions.append(pred)\n",
    "    \n",
    "    return kept_predictions\n",
    "\n",
    "def generate_submission(\n",
    "    models,\n",
    "    test_experiments,\n",
    "    particle_types,\n",
    "    base_dir,\n",
    "    patch_size,\n",
    "    stride_3d,\n",
    "    submission_file,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \"\"\"Generate submission with ensemble predictions and NMS\"\"\"\n",
    "    all_predictions = []\n",
    "    prediction_id = 0\n",
    "\n",
    "    for experiment in test_experiments:\n",
    "        print(f\"\\nProcessing experiment: {experiment}\")\n",
    "        zarr_path = os.path.join(\n",
    "            base_dir, \n",
    "            f\"test/static/ExperimentRuns/{experiment}/VoxelSpacing10.000/denoised.zarr\"\n",
    "        )\n",
    "        \n",
    "        if not os.path.exists(zarr_path):\n",
    "            continue\n",
    "        \n",
    "        predictions = predict_ensemble(\n",
    "            models=models,\n",
    "            zarr_path=zarr_path,\n",
    "            patch_size=patch_size,\n",
    "            stride_3d=stride_3d,\n",
    "            device=device,\n",
    "            threshold=0.75 \n",
    "        )\n",
    "        \n",
    "        filtered_preds = nms_3d(\n",
    "            predictions, \n",
    "            iou_threshold=0.3, \n",
    "            radius=15\n",
    "        )\n",
    "        \n",
    "        for pred in filtered_preds:\n",
    "            particle_probs = pred[\"particle_type_probs\"]\n",
    "            \n",
    "            for i, particle_type in enumerate(particle_types):\n",
    "                if particle_probs[i] >= 0.5:  \n",
    "                    all_predictions.append({\n",
    "                        \"id\": prediction_id,\n",
    "                        \"experiment\": experiment,\n",
    "                        \"particle_type\": particle_type,\n",
    "                        \"x\": round(float(pred[\"x\"]), 5),\n",
    "                        \"y\": round(float(pred[\"y\"]), 5),\n",
    "                        \"z\": round(float(pred[\"z\"]), 5)\n",
    "                    })\n",
    "                    prediction_id += 1\n",
    "\n",
    "    df = pd.DataFrame(all_predictions)\n",
    "    df.to_csv(submission_file, index=False)\n",
    "    print(f\"Saved {len(all_predictions)} predictions to {submission_file}\")    \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10033515,
     "sourceId": 84969,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "cryoet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
